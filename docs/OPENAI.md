# Интеграция OpenAI (Responses API + file_search) и Prompt Caching

Документ описывает настройку ИИ-ассистента для ООО «Терсан», загрузку внутренних PDF в vector store OpenAI и рекомендации по Prompt Caching.

## 1) Переменные окружения

Добавьте в `.env`:

```env
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-5
# Укажите после создания /docs_store create или заранее, если уже есть
# OPENAI_VECTOR_STORE_ID=vs_...
# Ключ для Prompt Caching (стабильный для одинаковых префиксов)
OPENAI_PROMPT_CACHE_KEY=tersan-assistant-v1
# Инструкции ассистента (статичные и русскоязычные)
OPENAI_INSTRUCTIONS=Ты корпоративный ассистент логистической компании ООО Терсан. Отвечай кратко, по делу и на русском языке. Используй внутренние документы, если доступны, и явно указывай, если информации недостаточно. Не выдумывай факты.

# Веб-поиск (опционально)
# Включить веб-поиск как инструмент модели
OPENAI_ENABLE_WEB_SEARCH=false
# Объём контента, который подтягивает инструмент: low | medium | high
OPENAI_WEB_SEARCH_CONTEXT_SIZE=medium
# Приблизительная локация пользователя (для локальных результатов)
# ISO-2 страна, произвольные city/region, IANA timezone
# OPENAI_WEB_SEARCH_COUNTRY=RU
# OPENAI_WEB_SEARCH_CITY=Kazan
# OPENAI_WEB_SEARCH_REGION=Tatarstan
# OPENAI_WEB_SEARCH_TIMEZONE=Europe/Moscow
```

## 2) Установка

```bash
pip install -r requirements.txt
```

## 3) Запуск

```bash
python -m app.main
```

## 4) Управление базой знаний (админ)

В Telegram от лица администратора (ID в `ADMIN_USER_IDS`):

- Создать хранилище: `/docs_store create tersan_docs` → бот вернёт `vs_...` и активирует его
- Использовать существующее: `/docs_store set vs_XXXXXXXX`
- Загрузка PDF: отправьте `/docs_upload` и прикрепите PDF к тому же сообщению

Рекомендации:
- После создания сохраните `OPENAI_VECTOR_STORE_ID` в `.env`, чтобы не задавать его заново после перезапуска
- Загружайте только актуальные и окончательные версии документов

## 5) Использование сотрудниками

Сотрудник пишет текстовый вопрос боту. Если `OPENAI_VECTOR_STORE_ID` задан, ассистент использует `file_search` и отвечает на основе внутренних PDF.

## 6) Prompt Caching (экономия и ускорение)

Prompt Caching включён автоматически в новых моделях (gpt-4o и новее). В проекте дополнительно используется `prompt_cache_key` для повышения стабильности кэша.

Рекомендации:
- Держите статичный префикс (инструкции и список tools) в начале промпта; переменную часть (вопрос пользователя) в конце
- Используйте единый `OPENAI_PROMPT_CACHE_KEY` для запросов с одинаковым статичным префиксом
- Не превышайте ~15 запросов/минуту на одну комбинацию «префикс + prompt_cache_key»
- Кэш-хиты возможны только для точных префиксов; срок жизни кэша обычно 5–10 минут простоя

Реализация:
- `app/services/openai_service.py` — в вызове `responses.create` передаются `instructions` и `prompt_cache_key`
- Там же при `OPENAI_ENABLE_WEB_SEARCH=true` автоматически добавляется инструмент `web_search_preview`. Можно включать/выключать геолокацию и менять `OPENAI_WEB_SEARCH_CONTEXT_SIZE`.

## 7) Память диалога (контекст)

Включена память чата на Redis:

- История хранится в `chat:{chat_id}:history` (последние N сообщений, N задаётся `CONV_MAX_HISTORY_MESSAGES`, по умолчанию 20)
- Краткая сводка длинной переписки хранится в `chat:{chat_id}:summary`
- При каждом ответе модель получает: сводку (если есть) + последние сообщения + текущий запрос
- При переполнении — вызывается авто-суммаризация и история подрезается

Переменные окружения:

```env
# Память диалога
CONV_MAX_HISTORY_MESSAGES=20
```

Где посмотреть код:

- `app/services/memory.py` — работа с Redis
- `app/services/openai_service.py` — сбор сообщений, ограничение токенов, авто-суммаризация

Проверка кэша:
- Смотрите `usage.prompt_tokens_details.cached_tokens` в ответе API; для коротких запросов (<1024 токенов) значение будет `0`

## 7) Диагностика

- Проверьте логи: корректность `OPENAI_API_KEY`, активность `OPENAI_VECTOR_STORE_ID`
- Ошибки OpenAI логируются через Loguru

---

При необходимости можно завести разные `prompt_cache_key` для разных отделов (если будут отличаться инструкции или список инструментов).


